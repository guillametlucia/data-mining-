{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Jorge Guillamet\\\\OneDrive\\\\lucia_tbjochina\\\\Data mining\\\\coursework-1-data\\\\coursework-1-data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\lib\\site-packages (24.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from task1_2 import process_text, text_stats\n",
    "from termcolor import colored\n",
    "from time import perf_counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "############################################################################################################\n",
    "################################### Read in data ##############################################\n",
    "###############################################################################\n",
    "# with open('inverted_index.json', 'r') as f:\n",
    "#     inverted_index = json.load(f) # tf\n",
    "candidate_passages = pd.read_csv('candidate-passages-top1000.tsv', sep='\\t', header=None)\n",
    "test_queries = pd.read_csv('test-queries.tsv', sep='\\t', header=None)\n",
    "training_data = pd.read_csv('training_data.tsv', sep='\\t', header=None, low_memory=False) \n",
    "\n",
    "# TF-IDF. Vector representation of documents and queries.\n",
    "all_pid = candidate_passages[1].unique().tolist()\n",
    "all_qid = test_queries[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(colored('Building index..', 'green', attrs=['reverse', 'blink']))\n",
    "# Create nested dictionary with terms as keys that map to another dictionary where documents are keys.\n",
    "inverted_index = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# For each passage, record the amount of time terms appear. \n",
    "done_pid = []\n",
    "for index, row in tqdm(training_data.iterrows()):\n",
    "    if row[1] not in done_pid:\n",
    "        vocab = process_text(row[3])\n",
    "        pid = row[1]\n",
    "        done_pid.append(pid)\n",
    "        for term, count in vocab.items():\n",
    "            inverted_index[term][pid] = count\n",
    "print(colored('Success\\n', 'green', attrs=['reverse', 'blink']))\n",
    "\n",
    "# Save output\n",
    "print(colored('Saving file..', 'green', attrs=['reverse', 'blink']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row s the header\n",
    "\n",
    "validation_data = pd.read_csv('validation_data.tsv', sep='\\t', header=None, low_memory=False) #MAYEB DONT WANT LOW MEMORY FALSE\n",
    "validation_data.columns = validation_data.iloc[0]\n",
    "validation_data = validation_data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>queries</th>\n",
       "      <th>passage</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082792</td>\n",
       "      <td>1000084</td>\n",
       "      <td>what does the golgi apparatus do to the proteins and lipids once they arrive ?</td>\n",
       "      <td>Start studying Bonding, Carbs, Proteins, Lipids. Learn vocabulary, terms, and more with flashcards, games, and other study tools.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      qid  ... relevancy\n",
       "1  1082792  ...       0.0\n",
       "\n",
       "[1 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "validation_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[7m\u001b[32mCalculating nt and idf..\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130648/130648 [00:00<00:00, 285326.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[7m\u001b[32mSuccess\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(colored('Calculating nt and idf..', 'green', attrs=['reverse', 'blink']))\n",
    "N = len(all_pid)\n",
    "logN = np.log(N)\n",
    "# Initialize an empty dictionary for nt and idf values\n",
    "nt_idf_dict = {}\n",
    "# Calculate nt and idf for each term\n",
    "for term, docs in tqdm(inverted_index.items()):\n",
    "    nt = len(docs)  # number of documents containing the term\n",
    "    idf = logN - np.log(nt)  # optimized calculation\n",
    "    nt_idf_dict[term] = [nt, idf]\n",
    "print(colored('Success\\n', 'green', attrs=['reverse', 'blink']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[7m\u001b[32mCalculating document lengths..\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "189877it [01:18, 2422.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[7m\u001b[32mSuccess\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k1 = 1.2\n",
    "k2 = 100\n",
    "b = 0.75\n",
    "\n",
    "print(colored('Calculating document lengths..', 'green', attrs=['reverse', 'blink']))\n",
    "doc_lengths_dict = {}\n",
    "for index, row in tqdm(candidate_passages.iterrows()):\n",
    "    pid = str(row[1])\n",
    "    passage = row[3]\n",
    "    length_passage = text_stats(passage, remove_stopwords=True)[2]\n",
    "    doc_lengths_dict[pid] = length_passage\n",
    "avg_dl = np.mean(list(doc_lengths_dict.values()))\n",
    "print(colored('Success\\n', 'green', attrs=['reverse', 'blink']))\n",
    "\n",
    "\n",
    "\n",
    "candidate_pids_per_qid = candidate_passages.groupby(0)[1].apply(lambda x: [str(pid) for pid in x]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[7m\u001b[32mCalculating scores..\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 105.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[7m\u001b[32mSuccess\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_bm25 = {qid: {} for qid in all_qid} # Initialize a dictionary to store the results\n",
    "print(colored('Calculating scores..', 'green', attrs=['reverse', 'blink']))\n",
    "for qid in tqdm(all_qid):\n",
    "    query = test_queries[test_queries[0] == qid][1].values[0]\n",
    "    query_vocab = process_text(query)# tokenize query\n",
    "    candidate_pids = candidate_pids_per_qid[qid]\n",
    "    for pid in candidate_pids:\n",
    "        bm25 = 0\n",
    "        for term, tf_q in query_vocab.items():\n",
    "            if term in inverted_index and pid in inverted_index[term].keys():\n",
    "                doc_length = doc_lengths_dict[pid]\n",
    "                tf_d = inverted_index[term][pid]\n",
    "                nt = nt_idf_dict[term][0]\n",
    "                bm25 = bm25 + np.log((N-nt + 0.5)/(nt+0.5))*(k1+1)*tf_d/(k1*((1-b)+b*(doc_length/avg_dl))+tf_d)*(k2+1)*tf_q/(k2+tf_q)\n",
    "        results_bm25[qid][pid] = bm25\n",
    "print(colored('Success\\n', 'green', attrs=['reverse', 'blink']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty results dataframe\n",
    "final = pd.DataFrame(columns=[\"qid\", \"pid\", \"score\"])\n",
    "row_count = 0\n",
    "\n",
    "# Loop through results and append to dataframe\n",
    "print(colored('Saving bm25 scores..', 'green', attrs=['reverse', 'blink']))\n",
    "for key in tqdm(results_bm25):\n",
    "    \n",
    "    # Sort the results by score, and select top 100\n",
    "    df = pd.Series(dict(sorted(results_bm25[key].items(), key=lambda item: item[1], reverse=True))).reset_index(name=\"score\")[0:100]\n",
    "    # Build dataframe out of the results using row_count as the index\n",
    "    to_concat = pd.concat([pd.DataFrame(np.repeat(key, len(df))), pd.DataFrame(df[\"index\"].astype(\"str\")), pd.DataFrame(df[\"score\"])], axis=1)\n",
    "    to_concat = to_concat.rename(columns={0: 'qid', 'index': 'pid'})\n",
    "    # Append to final dataframe\n",
    "    final = pd.concat([final, to_concat])\n",
    "    # Update row count\n",
    "    row_count += len(df)\n",
    "print(colored('Success\\n', 'green', attrs=['reverse', 'blink']))\n",
    "\n",
    "# Expected length of the DataFrame\n",
    "expected_length = 19290\n",
    "\n",
    "# Check the length of the DataFrame\n",
    "assert len(final) == expected_length, f\"Error: The length of the DataFrame is {len(final)}, but it should be {expected_length}\"\n",
    "\n",
    "# If the assertion passes, save the DataFrame\n",
    "final.to_csv(\"bm25.csv\", header=None, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
